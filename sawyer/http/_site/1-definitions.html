<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Definitions</title>
  <meta name="description" content="Information about the current work on the One-Shot Imitation Learning for the &quot;Sawyer&quot; robotic arm">
  <meta name="keywords" content="sawyer">
  <meta name="author" content="Hannes Thielke">

  <meta property="og:title" content="Definitions" />
  <meta property="og:description" content="Information about the current work on the One-Shot Imitation Learning for the "Sawyer" robotic arm
" />
  <meta property="og:site_name" content="One-Shot Imitation Learning" />
  <meta property="og:url" content="http://localhost:4000/NTU_robotics/1-definitions.html" />
  <meta property="og:locale" content="en_US" />
  <script type="application/ld+json">{"@context":"http://schema.org","@type":"WebPage","headline":"Definitions","author":{"@type":"Person","name":"Hannes Thielke"},"description":"Information about the current work on the One-Shot Imitation Learning for the "Sawyer" robotic arm
","url":"http://localhost:4000/NTU_robotics/1-definitions.html"}</script>

  <link rel="stylesheet" href="http://localhost:4000/NTU_robotics/css/main.css">

  <!-- Google Analytics -->

</head>


  <body>
    
    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="http://localhost:4000/NTU_robotics/">One-Shot Imitation Learning</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          <a class="page-link" href="http://localhost:4000/NTU_robotics/1-definitions.html">Definitions</a>
          
        
          
          <a class="page-link" href="http://localhost:4000/NTU_robotics/2-software.html">Software</a>
          
        
          
          <a class="page-link" href="http://localhost:4000/NTU_robotics/3-papers.html">Papers</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width" />

	<script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>
</head>

<h1 id="reinforcement-learning">Reinforcement Learning</h1>
<!-- drawn from https://blog.statsbot.co/introduction-to-imitation-learning-32334c3b1e7a -->

<figure display:="" inline-block="">
    <img src="http://localhost:4000/NTU_robotics/images/reinforcement_learning.png" alt="" style="height:7.5cm;" />
    <figcaption>Reinforcement Learning  <a href="https://blog.statsbot.co/introduction-to-imitation-learning-32334c3b1e7a">(source)</a> </figcaption>
  </figure>

<p>In a Reinforcement Learning process the agent gets a reward (positive or negative) for every action he does.
During the training the agent learns how to maximise the reward.</p>

<p>A reinforcement learning framework can be described as a Markov Decision Process:</p>

<script type="math/tex; mode=display">\langle S,A,R,T,\gamma \rangle</script>

<p>where</p>
<ul>
  <li>S is the set of states</li>
  <li>A is the set of actions</li>
  <li>R is the reward function <script type="math/tex">R(s,a):S \times A \rightarrow \mathbb{R}</script></li>
  <li>T is the transit function <script type="math/tex">T(s,a,s')=p(s' \mid a,s)</script></li>
  <li><script type="math/tex">\gamma</script> is the discounting factor that trades off the balance between the immediate reward and the future reward</li>
</ul>

<p>Policy function:</p>

<script type="math/tex; mode=display">\pi(s):S \rightarrow A</script>

<p>Further links:</p>

<ul>
  <li><a href="http://amunategui.github.io/reinforcement-learning/">Amunategui.github.io</a></li>
  <li><a href="https://www.youtube.com/watch?v=nSxaG_Kjw_w">Video about Reinforcement Learning</a> </li>
</ul>

<h1 id="imitation-learing-or-learning-by-demonstration-programming-by-example">Imitation Learing (or learning by demonstration, programming by example)</h1>
<p>Imitation Learning describes the process of training an agent to mimic a certain behaviour.
The agent tries to learn new skills by observing demonstrations of an expert.</p>

<p>The data collected during demonstration is saved in the form of observation-action pairs. <!-- drawn from paper ZERO-SHOT VISUAL IMITATION --></p>

<p>It is hereby assumed that there is an expert available from whom the agent can learn from.
This means that the agents skills are based on training the experts behaviour and cannot recover from failures in case the demonstration data had imperfections.</p>

<h2 id="policy">Policy</h2>
<p>The goal of Imitation Learning is to find a function that maps the current state to the action.
This function is referred to as <strong>policy</strong>. The success of a policy is measured by means of the total reward that the policy can achieve.</p>

<h1 id="attention-in-neural-networks">Attention in Neural Networks</h1>
<!-- drawn from http://akosiorek.github.io/ml/2017/10/14/visual-attention.html -->
<p>Informally, a neural attention mechanism equips a neural network with the ability to focus on a subset of its inputs (or features): it selects specific inputs.
There are two main attention mechanisms:</p>
<ul>
  <li>Hard attention</li>
  <li>Soft attention</li>
</ul>

<h1 id="convolutional-neural-networks">Convolutional Neural Networks</h1>
<p>helpful links:
<a href="https://www.youtube.com/watch?v=FmpDIaiMIeA">Youtube - ConvNets</a></p>

<h2 id="softmax-function">Softmax Function</h2>
<!-- drawn from https://en.wikipedia.org/wiki/Softmax_function -->
<p>The softmax function is a generalization of the logistic function that “squashes” a K-dimensional vector <script type="math/tex">\mathbf {z}</script> of arbitrary real values to a K-dimensional vector <script type="math/tex">\sigma (\mathbf {z} )</script> of real values, where each entry is in the range <script type="math/tex">(0, 1]</script>, and all the entries add up to 1. The function is given by</p>

<script type="math/tex; mode=display">\sigma (\mathbf {z} )_{j}={\frac {e^{z_{j}}}{\sum _{k=1}^{K}e^{z_{k}}}}</script>

<p>In a neural network this is used to squash the output values that indicate the probability into the range of 0 to 1 in a way that they add up to 1. This will make it easier to illustrate the probability of the outcome.</p>

<h2 id="cross-entropy-function">Cross-Entropy Function</h2>
<p><script type="math/tex">H(p,q)=-\sum _{x}p(x)\,\log q(x)</script></p>

<p>The cross-entropy function is a error function in a neural network that indicates how good the results of the network were.
Other used error functions are e.g. the classification error and the mean squared error.</p>

<h2 id="dilated-convolutions">Dilated Convolutions</h2>
<!-- drawn from https://www.youtube.com/watch?v=cGkjH_c4SwI -->

<figure display:="" inline-block="">
    <img src="http://localhost:4000/NTU_robotics/images/one-shot_imitator_training.png" alt="" style="height:5.5cm;" />
    <figcaption>Regular Convolution vs. Dilated Convolution </figcaption>
  </figure>

<h1 id="multilayer-perceptron-mlp">Multilayer perceptron MLP</h1>
<p>vanilla neural network</p>

<h1 id="dataset-aggregation-dagger">Dataset Aggregation DAGGER</h1>
<p>The <a href="files/a_reduction_of_imitation_learning_and_structured_prediction.pdf">DAGGER Algorithm</a> can be used to train a policy.</p>

<!---

  <figure display: inline-block>
    <img src="http://localhost:4000/NTU_robotics/images/topless_configuration/topless_step_17.jpg" alt="" style="height:6.5cm;">
    
  </figure>

&nbsp;
-->
<!--  This table was created with http://tableizer.journalistopia.com 
<figure>
<style type="text/css">
	table.tableizer-table {
		font-size: 12px;
		border: 1px solid #CCC; 
		font-family: Arial, Helvetica, sans-serif;
	} 
	.tableizer-table td {
		padding: 4px;
		margin: 3px;
		border: 1px solid #CCC;
	}
	.tableizer-table th {
		background-color: #104E8B; 
		color: #FFF;
		font-weight: bold;
	}
</style>
<table class="tableizer-table"  cellspacing="0">
<thead><tr class="tableizer-firstrow"><th>Radiometric Units</th><th>Symbol</th><th>Unit</th><th>Photometric Units</th><th>Symbol</th><th>Unit</th><th>Description</th></tr></thead><tbody>
 <tr><td>Radiant power</td><td>$$P$$</td><td>Watts [W]</td><td>Luminous flux</td><td>$$F$$</td><td>Lumens [lm]</td><td>total perceived power of light</td></tr>
 <tr><td>Radiant intensity</td><td>$$I$$</td><td>Watts per steradian [W/ster]</td><td>Luminous intensity</td><td>$$I_v$$</td><td>Candelas [cd = lm/ster]</td><td>perceived power emitted by a light source in a particular direction per unit solid angle</td></tr>
 <tr><td>Irradiance</td><td>$$E$$</td><td>Watts per square metre [W/m2]</td><td>Illuminance</td><td>$$E_v$$</td><td>Lux [lx = lm/m2]</td><td>total luminous flux incident on a surface, per unit area</td></tr>
</tbody></table>
</figure>
<figcaption>Overview of important optical quantities <a href="">(source)</a></figcaption>

<br>

-->

      </div>
    </main>

    <footer class="site-footer">
  <div class="wrapper">
    <div class="footer-col-wrapper" >
    <div class="footer-nav">
        
          
          <a class="page-link" href="http://localhost:4000/NTU_robotics/1-definitions.html">Definitions</a>
          
        
          
          <a class="page-link" href="http://localhost:4000/NTU_robotics/2-software.html">Software</a>
          
        
          
          <a class="page-link" href="http://localhost:4000/NTU_robotics/3-papers.html">Papers</a>
          
        
          
        
          
        
    </div>
    </div>
      <h2 class="footer-heading"><a href="http://localhost:4000/NTU_robotics/">One-Shot Imitation Learning</a> - <a href="https://creativecommons.org/licenses/by-sa/4.0/">cc-by-sa</a> <a href="https://github.com/HannesThielke">Hannes Thielke</a> - 2018.</h2> 
  </div>
</footer>


  </body>

</html>
